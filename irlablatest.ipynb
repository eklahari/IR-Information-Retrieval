{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3333dfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0  1  2  3  4\n",
      "able         0  0  0  0  1\n",
      "additional   1  0  0  0  0\n",
      "after        0  1  0  0  0\n",
      "be           0  0  0  0  1\n",
      "better       0  0  0  1  0\n",
      "control      0  0  1  0  0\n",
      "experiment   0  1  0  0  0\n",
      "for          0  0  0  0  1\n",
      "information  1  0  0  0  0\n",
      "is           0  0  1  1  0\n",
      "list         0  0  0  1  0\n",
      "make         0  0  0  0  1\n",
      "more         0  0  1  0  0\n",
      "need         1  0  1  0  0\n",
      "reading      0  1  0  0  0\n",
      "realized     0  1  0  0  0\n",
      "replicate    0  0  0  0  1\n",
      "rock         0  0  0  1  0\n",
      "set          0  0  1  0  0\n",
      "should       0  0  0  1  0\n",
      "some         1  0  0  0  0\n",
      "student      0  0  0  1  0\n",
      "students     0  0  0  0  1\n",
      "that         1  1  0  0  0\n",
      "the          0  1  0  1  1\n",
      "to           0  0  0  0  2\n",
      "trials       0  0  1  0  0\n",
      "up           0  0  1  0  0\n",
      "we           1  0  0  0  0\n",
      "what         0  0  1  1  0\n",
      "would        1  0  0  0  0\n",
      "you          0  0  1  0  0\n"
     ]
    }
   ],
   "source": [
    "# Import pandas for dataframe \n",
    "import pandas as pd \n",
    "\n",
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    'Some additional information that we would need',\n",
    "    'After reading the experiment, I realized that',\n",
    "    'What you need is more trials, a control set up',\n",
    "    'The student should list what rock is better',\n",
    "    'For the students to be able to make a replicate'\n",
    "]\n",
    "\n",
    "# Construct a dataframe\n",
    "doc = pd.DataFrame(data, columns=['response'])\n",
    "\n",
    "# Activate CountVectorizer\n",
    "vect = CountVectorizer()  \n",
    "vects = vect.fit_transform(doc['response'])\n",
    "\n",
    "# Construct term-document incidence matrix\n",
    "td = pd.DataFrame(vects.todense(), columns=vect.get_feature_names_out())\n",
    "term_document_matrix = td.T\n",
    "\n",
    "# Print the term-document incidence matrix\n",
    "print(term_document_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99829073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0  1  2  3  4\n",
      "able         0  0  0  0  1\n",
      "additional   1  0  0  0  0\n",
      "after        0  1  0  0  0\n",
      "be           0  0  0  0  1\n",
      "better       0  0  0  1  0\n",
      "control      0  0  1  0  0\n",
      "document1    1  0  0  0  0\n",
      "document2    0  1  0  0  0\n",
      "document3    0  0  1  0  0\n",
      "document4    0  0  0  1  0\n",
      "document5    0  0  0  0  1\n",
      "experiment   0  1  0  0  0\n",
      "for          0  0  0  0  1\n",
      "information  1  0  0  0  0\n",
      "is           0  0  1  1  0\n",
      "list         0  0  0  1  0\n",
      "make         0  0  0  0  1\n",
      "more         0  0  1  0  0\n",
      "need         1  0  1  0  0\n",
      "reading      0  1  0  0  0\n",
      "realized     0  1  0  0  0\n",
      "replicate    0  0  0  0  1\n",
      "rock         0  0  0  1  0\n",
      "set          0  0  1  0  0\n",
      "should       0  0  0  1  0\n",
      "some         1  0  0  0  0\n",
      "student      0  0  0  1  0\n",
      "students     0  0  0  0  1\n",
      "that         1  1  0  0  0\n",
      "the          0  1  0  1  1\n",
      "to           0  0  0  0  1\n",
      "trials       0  0  1  0  0\n",
      "up           0  0  1  0  0\n",
      "we           1  0  0  0  0\n",
      "what         0  0  1  1  0\n",
      "would        1  0  0  0  0\n",
      "you          0  0  1  0  0\n",
      "\n",
      "Boolean Query Result:\n",
      "   query_result\n",
      "0             2\n",
      "1             0\n",
      "2             0\n",
      "3             0\n",
      "4             0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    'document1: Some additional information that we would need...',\n",
    "    'document2: After reading the experiment, I realized that...',\n",
    "    'document3: What you need is more trials, a control set up...',\n",
    "    'document4: The student should list what rock is better...',\n",
    "    'document5: For the students to be able to make a replicate...'\n",
    "]\n",
    "\n",
    "# Construct a dataframe\n",
    "doc = pd.DataFrame(data, columns=['response'])\n",
    "\n",
    "# Activate CountVectorizer with binary=True for boolean values\n",
    "vect = CountVectorizer(binary=True)  \n",
    "vects = vect.fit_transform(doc['response'])\n",
    "\n",
    "# Construct term-document incidence matrix with boolean values\n",
    "td = pd.DataFrame(vects.todense(), columns=vect.get_feature_names_out())\n",
    "term_document_matrix = td.T\n",
    "\n",
    "# Print the term-document incidence matrix\n",
    "print(term_document_matrix)\n",
    "\n",
    "# Boolean query processing example\n",
    "def boolean_query(query, term_document_matrix):\n",
    "    terms = vect.transform([query]).todense()\n",
    "    result = term_document_matrix.T.dot(terms.T)\n",
    "    result.columns = ['query_result']\n",
    "    return result\n",
    "\n",
    "# Example boolean query\n",
    "query_result = boolean_query('additional AND information', term_document_matrix)\n",
    "print(\"\\nBoolean Query Result:\")\n",
    "print(query_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a326505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Term-Document Incidence Matrix:\n",
      "       0  1  2\n",
      "are    1  1  0\n",
      "birds  0  0  1\n",
      "can    0  0  1\n",
      "cats   1  0  0\n",
      "cute   1  0  0\n",
      "doc1   1  0  0\n",
      "doc2   0  1  0\n",
      "doc3   0  0  1\n",
      "dogs   0  1  0\n",
      "fly    0  0  1\n",
      "loyal  0  1  0\n",
      "\n",
      "Boolean Query Result:\n",
      "   query_result\n",
      "0             2\n",
      "1             0\n",
      "2             0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample data with simpler sentences\n",
    "data = [\n",
    "    'doc1: Cats are cute.',\n",
    "    'doc2: Dogs are loyal.',\n",
    "    'doc3: Birds can fly.',\n",
    "]\n",
    "\n",
    "# Construct a dataframe\n",
    "doc = pd.DataFrame(data, columns=['response'])\n",
    "\n",
    "# Activate CountVectorizer with binary=True for boolean values\n",
    "vect = CountVectorizer(binary=True)  \n",
    "vects = vect.fit_transform(doc['response'])\n",
    "\n",
    "# Construct term-document incidence matrix with boolean values\n",
    "td = pd.DataFrame(vects.todense(), columns=vect.get_feature_names_out())\n",
    "term_document_matrix = td.T\n",
    "\n",
    "# Print the term-document incidence matrix\n",
    "print(\"\\nTerm-Document Incidence Matrix:\")\n",
    "print(term_document_matrix)\n",
    "\n",
    "# Boolean query processing example\n",
    "def boolean_query(query, term_document_matrix):\n",
    "    terms = vect.transform([query]).todense()\n",
    "    result = term_document_matrix.T.dot(terms.T)\n",
    "    result.columns = ['query_result']\n",
    "    return result\n",
    "\n",
    "# Example boolean query\n",
    "query_result = boolean_query('cats AND cute', term_document_matrix)\n",
    "print(\"\\nBoolean Query Result:\")\n",
    "print(query_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0159cde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new home sales top forecasts', 'home sales rise in july', 'increase in home sales in july', 'july new home sales rise']\n",
      "\n",
      "Unique Terms:\n",
      "{'sales', 'in', 'rise', 'july', 'increase', 'home', 'top', 'forecasts', 'new'}\n",
      "\n",
      "Inverted Index:\n",
      "{'new': {0, 3}, 'home': {0, 1, 2, 3}, 'sales': {0, 1, 2, 3}, 'top': {0}, 'forecasts': {0}, 'rise': {1, 3}, 'in': {1, 2}, 'july': {1, 2, 3}, 'increase': {2}}\n",
      "\n",
      "Posting list for 'home AND top': [0]\n",
      "Posting list for 'july OR increase': [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Sample data with simpler sentences\n",
    "Doc_1 = \"new home sales top forecasts\"\n",
    "Doc_2 = \"home sales rise in july\"\n",
    "Doc_3 = \"increase in home sales in july\"\n",
    "Doc_4 = \"july new home sales rise\"\n",
    "\n",
    "Docs = [Doc_1, Doc_2, Doc_3, Doc_4]\n",
    "print(Docs)\n",
    "\n",
    "# Getting unique terms in the documents\n",
    "unique_terms = set()\n",
    "for doc in Docs:\n",
    "    for term in doc.split():\n",
    "        unique_terms.add(term)\n",
    "print(\"\\nUnique Terms:\")\n",
    "print(unique_terms)\n",
    "\n",
    "# Creating inverted index in the form of a dictionary\n",
    "inverted_index = {}\n",
    "for i, doc in enumerate(Docs):\n",
    "    for term in doc.split():\n",
    "        if term in inverted_index:\n",
    "            inverted_index[term].add(i)\n",
    "        else:\n",
    "            inverted_index[term] = {i}\n",
    "print(\"\\nInverted Index:\")\n",
    "print(inverted_index)\n",
    "\n",
    "# Boolean operations on postings lists for Boolean search operations\n",
    "\n",
    "# \"OR\" operation\n",
    "def or_postings(posting1, posting2):\n",
    "    p1 = 0\n",
    "    p2 = 0\n",
    "    result = list()\n",
    "    while p1 < len(posting1) and p2 < len(posting2):\n",
    "        if posting1[p1] == posting2[p2]:\n",
    "            result.append(posting1[p1])\n",
    "            p1 += 1\n",
    "            p2 += 1\n",
    "        elif posting1[p1] > posting2[p2]:\n",
    "            result.append(posting2[p2])\n",
    "            p2 += 1\n",
    "        else:\n",
    "            result.append(posting1[p1])\n",
    "            p1 += 1\n",
    "    while p1 < len(posting1):\n",
    "        result.append(posting1[p1])\n",
    "        p1 += 1\n",
    "    while p2 < len(posting2):\n",
    "        result.append(posting2[p2])\n",
    "        p2 += 1\n",
    "    return result\n",
    "\n",
    "# \"AND\" operation\n",
    "def and_postings(posting1, posting2):\n",
    "    p1 = 0\n",
    "    p2 = 0\n",
    "    result = list()\n",
    "    while p1 < len(posting1) and p2 < len(posting2):\n",
    "        if posting1[p1] == posting2[p2]:\n",
    "            result.append(posting1[p1])\n",
    "            p1 += 1\n",
    "            p2 += 1\n",
    "        elif posting1[p1] > posting2[p2]:\n",
    "            p2 += 1\n",
    "        else:\n",
    "            p1 += 1\n",
    "    return result\n",
    "\n",
    "# \"AND\" operation for \"home\" and \"top\"\n",
    "pl_1 = list(inverted_index['home'])\n",
    "pl_2 = list(inverted_index['top'])\n",
    "and_result = and_postings(pl_1, pl_2)\n",
    "print(\"\\nPosting list for 'home AND top':\", and_result)\n",
    "\n",
    "# \"OR\" operation for \"july\" and \"increase\"\n",
    "pl_1 = list(inverted_index['july'])\n",
    "pl_2 = list(inverted_index['increase'])\n",
    "or_result = or_postings(pl_1, pl_2)\n",
    "print(\"Posting list for 'july OR increase':\", or_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26a11dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new home sales top forecasts', 'home sales rise in july', 'increase in home sales in july', 'july new home sales rise']\n",
      "\n",
      "Unique Terms:\n",
      "{'sales', 'in', 'rise', 'july', 'increase', 'home', 'top', 'forecasts', 'new'}\n",
      "\n",
      "Inverted Index:\n",
      "{'new': [0, 3], 'home': [0, 1, 2, 3], 'sales': [0, 1, 2, 3], 'top': [0], 'forecasts': [0], 'rise': [1, 3], 'in': [1, 2, 2], 'july': [1, 2, 3], 'increase': [2]}\n",
      "\n",
      "Posting list for 'home AND top': [0]\n",
      "Posting list for 'july OR increase': [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Sample data with simpler sentences\n",
    "Doc_1 = \"new home sales top forecasts\"\n",
    "Doc_2 = \"home sales rise in july\"\n",
    "Doc_3 = \"increase in home sales in july\"\n",
    "Doc_4 = \"july new home sales rise\"\n",
    "\n",
    "Docs = [Doc_1, Doc_2, Doc_3, Doc_4]\n",
    "print(Docs)\n",
    "\n",
    "# Getting unique terms in the documents\n",
    "unique_terms = set()\n",
    "for doc in Docs:\n",
    "    for term in doc.split():\n",
    "        unique_terms.add(term)\n",
    "print(\"\\nUnique Terms:\")\n",
    "print(unique_terms)\n",
    "\n",
    "# Creating inverted index in the form of a dictionary\n",
    "inverted_index = {}\n",
    "for i, doc in enumerate(Docs):\n",
    "    for term in doc.split():\n",
    "        if term in inverted_index:\n",
    "            inverted_index[term].append(i)\n",
    "        else:\n",
    "            inverted_index[term] = [i]\n",
    "print(\"\\nInverted Index:\")\n",
    "print(inverted_index)\n",
    "\n",
    "# Boolean operations on postings lists for Boolean search operations\n",
    "\n",
    "# \"OR\" operation\n",
    "def or_postings(posting1, posting2):\n",
    "    p1 = 0\n",
    "    p2 = 0\n",
    "    result = list()\n",
    "    while p1 < len(posting1) and p2 < len(posting2):\n",
    "        if posting1[p1] == posting2[p2]:\n",
    "            result.append(posting1[p1])\n",
    "            p1 += 1\n",
    "            p2 += 1\n",
    "        elif posting1[p1] > posting2[p2]:\n",
    "            result.append(posting2[p2])\n",
    "            p2 += 1\n",
    "        else:\n",
    "            result.append(posting1[p1])\n",
    "            p1 += 1\n",
    "    while p1 < len(posting1):\n",
    "        result.append(posting1[p1])\n",
    "        p1 += 1\n",
    "    while p2 < len(posting2):\n",
    "        result.append(posting2[p2])\n",
    "        p2 += 1\n",
    "    return result\n",
    "\n",
    "# \"AND\" operation\n",
    "def and_postings(posting1, posting2):\n",
    "    p1 = 0\n",
    "    p2 = 0\n",
    "    result = list()\n",
    "    while p1 < len(posting1) and p2 < len(posting2):\n",
    "        if posting1[p1] == posting2[p2]:\n",
    "            result.append(posting1[p1])\n",
    "            p1 += 1\n",
    "            p2 += 1\n",
    "        elif posting1[p1] > posting2[p2]:\n",
    "            p2 += 1\n",
    "        else:\n",
    "            p1 += 1\n",
    "    return result\n",
    "\n",
    "# \"AND\" operation for \"home\" and \"top\"\n",
    "pl_1 = list(inverted_index['home'])\n",
    "pl_2 = list(inverted_index['top'])\n",
    "and_result = and_postings(pl_1, pl_2)\n",
    "print(\"\\nPosting list for 'home AND top':\", and_result)\n",
    "\n",
    "# \"OR\" operation for \"july\" and \"increase\"\n",
    "pl_1 = list(inverted_index['july'])\n",
    "pl_2 = list(inverted_index['increase'])\n",
    "or_result = or_postings(pl_1, pl_2)\n",
    "print(\"Posting list for 'july OR increase':\", or_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5667aff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
