{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9Rft3foGzp6lIfQXvRstI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eklahari/IR-Information-Retrieval/blob/main/positionalindex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positional Index**"
      ],
      "metadata": {
        "id": "CT5znLGc2JuS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CypotutX2I-v",
        "outputId": "d39b453f-1be6-4e3e-c699-7a6cde44a889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents containing the phrase 'sample text for testing': [1, 2]\n",
            "{'this': {1: [1]}, 'is': {1: [2]}, 'a': {1: [3]}, 'sample': {1: [4, 8], 2: [1], 3: [2]}, 'document': {1: [5], 3: [3]}, 'it': {1: [6]}, 'contains': {1: [7]}, 'text': {1: [9], 2: [2]}, 'for': {1: [10], 2: [3], 3: [4]}, 'testing': {1: [11], 2: [4]}, 'another': {3: [1]}, 'demonstration': {3: [5]}}\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "\n",
        "def build_positional_index(documents):\n",
        "    positional_index = {}\n",
        "    for doc_id, doc in enumerate(documents, start=1):\n",
        "        doc = doc.lower()\n",
        "        doc = ''.join([char for char in doc if char not in string.punctuation])\n",
        "        terms = doc.split()\n",
        "        position = 0\n",
        "        for term in terms:\n",
        "            position += 1\n",
        "            if term in positional_index:\n",
        "                if doc_id in positional_index[term]:\n",
        "                    positional_index[term][doc_id].append(position)\n",
        "                else:\n",
        "                    positional_index[term][doc_id] = [position]\n",
        "            else:\n",
        "                positional_index[term] = {doc_id: [position]}\n",
        "    return positional_index\n",
        "\n",
        "def process_phrase_query(phrase, positional_index):\n",
        "    phrase = phrase.lower()\n",
        "    terms = phrase.split()\n",
        "    results = set()\n",
        "\n",
        "    # Find documents containing the first term\n",
        "    first_term = terms[0]\n",
        "    if first_term in positional_index:\n",
        "        candidate_docs = set(positional_index[first_term].keys())\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "    for doc_id in candidate_docs:\n",
        "        positions = positional_index[first_term][doc_id]\n",
        "        found = False\n",
        "        for position in positions:\n",
        "            valid_sequence = True\n",
        "            for i, term in enumerate(terms[1:], start=1):\n",
        "                if doc_id in positional_index[term] and position + i in positional_index[term][doc_id]:\n",
        "                    continue\n",
        "                else:\n",
        "                    valid_sequence = False\n",
        "                    break\n",
        "            if valid_sequence:\n",
        "                results.add(doc_id)\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            continue\n",
        "\n",
        "    return list(results)\n",
        "\n",
        "# Sample documents as content without numbering\n",
        "documents = [\n",
        "    \"this is a sample document. it contains sample text for testing.\",\n",
        "    \"sample text for testing.\",\n",
        "    \"another sample document for demonstration.\"\n",
        "]\n",
        "\n",
        "# Build the positional index\n",
        "positional_index = build_positional_index(documents)\n",
        "\n",
        "# Example phrase query\n",
        "query = \"sample text for testing\"\n",
        "\n",
        "# Process the phrase query\n",
        "results = process_phrase_query(query, positional_index)\n",
        "\n",
        "if results:\n",
        "    print(f\"Documents containing the phrase '{query}': {results}\")\n",
        "else:\n",
        "    print(f\"No documents found for the phrase '{query}'.\")\n",
        "print(positional_index)"
      ]
    }
  ]
}